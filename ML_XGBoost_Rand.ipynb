{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, f1_score\n",
    "from sklearn.metrics import make_scorer, precision_recall_curve, auc\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from bayes_opt import BayesianOptimization\n",
    "#from sklearn.experimental import enable_halving_search_cv \n",
    "#from sklearn.model_selection import HalvingRandomSearchCV\n",
    "#from sklearn.model_selection import HalvingGridSearchCV \n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Menu\n",
    "\n",
    "<a name=\"navegacao\"></a>\n",
    "\n",
    "## 1) [Preparação dos dados](#parte1)\n",
    "- 1.1 [Leitura base principal](#principal)\n",
    "- 1.2 [Leitura base mes](#mes)\n",
    "- 1.3 [Leitura base hora](#hora)\n",
    "- 1.4 [Merge principal e base mensal](#merge1)\n",
    "- 1.5 [Merge principal e base hora](#merge2)\n",
    "- 1.6 [Confere marcação](#marcacao)\n",
    "\n",
    "\n",
    "## 2 [Salvando as bases de treino](#parte2)\n",
    "- 2.1 [Salvando base com histórico](#comhist)\n",
    "- 2.2 [Salvando base sem histórico](#semhist)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"principal\"></a>\n",
    "\n",
    "## 1.1) Leitura base principal\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = pd.read_csv(\"BNDES_UNIFICADO.csv\",converters={'CNPJ8': str,'INTERMEDIARIA': str},\n",
    "                 delimiter=\";\" , encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df.PORTE_RECEITA,df.SITUACAO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df.Porte_Cliente,df.SITUACAO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pd.crosstab(df.CUSTO, df.SITUACAO )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pd.crosstab(df.NATJUR, df.SITUACAO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df.EMPRESA_PUBLICA, df.SITUACAO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df.INDIRETA, df.SITUACAO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df.INOVACAO, df.SITUACAO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df.TESOURO, df.SITUACAO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df.SOCIO_PJ, df.SITUACAO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df.loc[ (df['CAPITAL_SOCIAL']<1)     ,'CAPITAL_SOCIAL']    = 1\n",
    "df.loc[ (df['IDADE']<1)              ,'IDADE']             = 1\n",
    "df.loc[ (df['NCONTRATOS']<1)         ,'NCONTRATOS']        = 1\n",
    "df.loc[ (df['NFILIAIS']<1)           ,'NFILIAIS']          = 1\n",
    "df.loc[ (df['IDADE_SOCIOS']<1)       ,'IDADE_SOCIOS']      = 1\n",
    "df.loc[ (df['QTDSOCIOS']<1)          ,'QTDSOCIOS']         = 1\n",
    "df.loc[ (df['MEDIA_JUROS']<1)        ,'MEDIA_JUROS']       = 1\n",
    "df.loc[ (df['PRAZO_AMORTIZACAO']<1)  ,'PRAZO_AMORTIZACAO'] = 1\n",
    "df.loc[ (df['PRAZO_CARENCIA']<1)     ,'PRAZO_CARENCIA']    = 1\n",
    "df.loc[ (df['VALOR_CONTRATO']<1)     ,'VALOR_CONTRATO']    = 1\n",
    "df.loc[ (df['VALOR_DESENBOLSO']<1)   ,'VALOR_DESENBOLSO']  = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['enc_NATJUR']        = df.NATJUR.astype(\"category\").cat.codes\n",
    "df['enc_GARANTIA']      = df.GARANTIA.astype(\"category\").cat.codes\n",
    "df['enc_INSTRUMENTO']   = df.INSTRUMENTO.astype(\"category\").cat.codes\n",
    "df['enc_CUSTO']         = df.CUSTO.astype(\"category\").cat.codes\n",
    "df['enc_PORTE_CLIENTE'] = df.Porte_Cliente.astype(\"category\").cat.codes\n",
    "df['enc_PORTE_RECEITA'] = df.PORTE_RECEITA.astype(\"category\").cat.codes\n",
    "df['enc_SITUACAO']      = df.SITUACAO.astype(\"category\").cat.codes\n",
    "df['enc_UF']            = df.UF.astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['ln_capsoc']        = np.log(df['CAPITAL_SOCIAL']+1)\n",
    "df['ln_idade']         = np.log(df['IDADE']+1)\n",
    "df['ln_contratos']     = np.log(df['NCONTRATOS']+1)\n",
    "df['ln_filiais']       = np.log(df['NFILIAIS']+1)\n",
    "df['ln_sociosage']     = np.log(df['IDADE_SOCIOS']+1)\n",
    "df['ln_qtdsocios']     = np.log(df['QTDSOCIOS']+1)\n",
    "df['ln_juros']         = np.log(df['MEDIA_JUROS']+1)\n",
    "df['ln_amortizacao']   = np.log(df['PRAZO_AMORTIZACAO']+1)\n",
    "df['ln_carencia']      = np.log(df['PRAZO_CARENCIA']+1)\n",
    "df['ln_vlrcontrato']   = np.log(df['VALOR_CONTRATO']+1)\n",
    "df['ln_vlrdesembolso'] = np.log(df['VALOR_DESENBOLSO']+1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo sem histórico foi treinado com as variáveis na seguinte ordem:\n",
    "['faixa_hora', 'vl_medio_mes_atual', 'dif_vl_1', 'tres_prim_dig_codbarras', 'pagador_pf', 'dif_vl_4', 'dia_do_mes', 'qtd_operacoes_mes_corrente', 'vl_medio_dia_corrente', 'sec_dig', 'qtd_operacoes_dia_corrente', 'qtd_trn_60min', 'centavos', 'dia_da_semana']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "files = df.columns\n",
    "#selected_files = files.str.contains('ln_|enc_|INDIRETA|EMPRESA_PUBLICA|INOVACAO|TESOURO|SOCIO_PJ')\n",
    "selected_files = files.str.contains('ln_|INDIRETA|EMPRESA_PUBLICA|INOVACAO|TESOURO|SOCIO_PJ')\n",
    "atributes = files[selected_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[atributes].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[atributes].describe().transpose()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE: Synthetic Minority Oversampling Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y0 = df['SITUACAO'].values.reshape(-1, 1)\n",
    "#y0 = df['SITUACAO'].values\n",
    "X0 = df[atributes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import joblib\n",
    "#scaler = joblib.load(\"scaler.saved\") \n",
    "\n",
    "from numpy import asarray\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "# transform data\n",
    "X0 = scaler.fit_transform(df[atributes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base sintética: treino e teste\n",
    "x_train  , x_test0 , y_train, y_test0 = train_test_split(X0, y0, test_size = 0.4, random_state=123)\n",
    "\n",
    "# base sintética: teste e out of sample\n",
    "x_test , x_out , y_test, y_out = train_test_split(x_test0, y_test0, test_size = 0.4, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize the new class distribution\n",
    "#counter0 = Counter(y_train)\n",
    "#counter1 = Counter(y_test)\n",
    "#counter2 = Counter(y_out)\n",
    "#print(counter0, counter1, counter2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "gr_range = ['depthwise','lossguide']\n",
    "bs_range = ['gbtree','dart']\n",
    "\n",
    "def gbm_xgb(learning_rate, max_depth, gamma, min_child_weight, subsample, eta, reg_alpha, reg_lambda,\n",
    "            n_estimators, max_delta_step, max_leaves, max_cat_threshold, grow_policy, scale_pos_weight, \n",
    "            booster , max_bin):\n",
    "    model = xgb.XGBClassifier(\n",
    "                  learning_rate       = learning_rate,\n",
    "                  max_depth           = int(max_depth),\n",
    "                  gamma               = gamma,\n",
    "                  min_child_weight    = int(min_child_weight),\n",
    "                  subsample           = subsample,\n",
    "                  eta                 = eta,\n",
    "                  reg_alpha           = reg_alpha,\n",
    "                  reg_lambda          = reg_lambda,\n",
    "                  n_estimators        = int(n_estimators),\n",
    "                  max_delta_step      = max_delta_step,\n",
    "                  max_leaves          = int(max_leaves),\n",
    "                  max_bin             = int(max_bin),\n",
    "                  max_cat_threshold   = int(max_cat_threshold),\n",
    "                  booster             = bs_range[int(booster)],\n",
    "                  grow_policy         = gr_range[int(grow_policy)],\n",
    "                  scale_pos_weight    = scale_pos_weight,\n",
    "                  missing             = 0,\n",
    "                  random_state        = 666,\n",
    "                  nthread =10 )\n",
    "    \n",
    "    model.fit(x_train, y_train, verbose=False)\n",
    "    pred_labels = model.predict(x_test)\n",
    "    return roc_auc_score(y_test, pred_labels)\n",
    "\n",
    "params_xgb = {\n",
    "    'learning_rate'          : (0.010 ,0.500),\n",
    "    'max_depth'              : (2.000 ,11.00),\n",
    "    'gamma'                  : (1.000 ,100.0),\n",
    "    'min_child_weight'       : (1.000 ,100.0),\n",
    "    'subsample'              : (0.222 ,0.999),\n",
    "    'eta'                    : (0.005 ,0.500),\n",
    "    'reg_alpha'              : (0.050 ,10.00),\n",
    "    'reg_lambda'             : (0.050 ,10.00),\n",
    "    'n_estimators'           : (50.00 ,500.0),\n",
    "    'max_delta_step'         : (0.005 ,5.000),\n",
    "    'max_leaves'             : (2.000 ,50.00),\n",
    "    'max_bin'                : (2.000 ,100.0),\n",
    "    'max_cat_threshold'      : (2.000 ,100.0),\n",
    "    'booster'                : (0.001 ,1.000),\n",
    "    'max_cat_threshold'      : (5.000 ,50.00),\n",
    "    'grow_policy'            : (0.001 ,1.000),\n",
    "    'scale_pos_weight'       : (0.222 ,100.0),\n",
    "}\n",
    "   \n",
    "xgb0 = BayesianOptimization(f=gbm_xgb, pbounds=params_xgb, random_state=123) \n",
    "xgb0.maximize(init_points=30, n_iter=350, acq='ucb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_xgb = xgb0.max['params']\n",
    "params_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate       = xgb0.max['params']['learning_rate']\n",
    "max_depth           = int(xgb0.max['params']['max_depth'])\n",
    "gamma               = xgb0.max['params']['gamma']\n",
    "min_child_weight    = int(xgb0.max['params']['min_child_weight'])\n",
    "subsample           = xgb0.max['params']['subsample']\n",
    "eta                 = xgb0.max['params']['eta']\n",
    "reg_alpha           = xgb0.max['params']['reg_alpha']\n",
    "reg_lambda          = xgb0.max['params']['reg_lambda']\n",
    "n_estimators        = int(xgb0.max['params']['n_estimators'])\n",
    "max_delta_step      = xgb0.max['params']['max_delta_step']\n",
    "max_leaves          = int(xgb0.max['params']['max_leaves'])\n",
    "max_bin             = int(xgb0.max['params']['max_bin'])\n",
    "max_cat_threshold   = int(xgb0.max['params']['max_cat_threshold'])\n",
    "booster             = bs_range[int(xgb0.max['params']['booster'])]\n",
    "grow_policy         = gr_range[int(xgb0.max['params']['grow_policy'])]\n",
    "scale_pos_weight    = xgb0.max['params']['scale_pos_weight']\n",
    "\n",
    "    \n",
    "print('\\n learning_rate:'     , learning_rate,\n",
    "      '\\n max_depth:'         , max_depth,\n",
    "      '\\n gamma:'             , gamma,\n",
    "      '\\n min_child_weight:'  , min_child_weight,\n",
    "      '\\n subsample:'         , subsample,\n",
    "      '\\n eta:'               , eta,\n",
    "      '\\n reg_alpha:'         , reg_alpha,\n",
    "      '\\n reg_lambda:'        , reg_lambda,\n",
    "      '\\n n_estimators:'      , n_estimators,\n",
    "      '\\n max_delta_step:'    , max_delta_step,\n",
    "      '\\n max_leaves:'        , max_leaves,\n",
    "      '\\n max_bin:'           , max_bin,\n",
    "      '\\n max_cat_threshold:' , max_cat_threshold,\n",
    "      '\\n grow_policy:'       , grow_policy,\n",
    "      '\\n booster:'           , booster,\n",
    "      '\\n scale_pos_weight:'  , scale_pos_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 18s, sys: 10.7 s, total: 3min 28s\n",
      "Wall time: 6.54 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;background-color: white;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eta=0.04618151922455719,\n",
       "              eval_metric=None, feature_types=None, gamma=76.60460130289049,\n",
       "              gpu_id=None, grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.10516925068359771,\n",
       "              max_bin=58, max_cat_threshold=9, max_cat_to_onehot=None,\n",
       "              max_delta_step=4.427207497244322, max_depth=7, max_leaves=36,\n",
       "              min_child_weight=2, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=317, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eta=0.04618151922455719,\n",
       "              eval_metric=None, feature_types=None, gamma=76.60460130289049,\n",
       "              gpu_id=None, grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.10516925068359771,\n",
       "              max_bin=58, max_cat_threshold=9, max_cat_to_onehot=None,\n",
       "              max_delta_step=4.427207497244322, max_depth=7, max_leaves=36,\n",
       "              min_child_weight=2, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=317, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eta=0.04618151922455719,\n",
       "              eval_metric=None, feature_types=None, gamma=76.60460130289049,\n",
       "              gpu_id=None, grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.10516925068359771,\n",
       "              max_bin=58, max_cat_threshold=9, max_cat_to_onehot=None,\n",
       "              max_delta_step=4.427207497244322, max_depth=7, max_leaves=36,\n",
       "              min_child_weight=2, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=317, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, ...)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "cbbb= xgb.XGBClassifier(learning_rate     = learning_rate,\n",
    "                        max_depth         = max_depth,\n",
    "                        gamma             = gamma,\n",
    "                        min_child_weight  = min_child_weight,\n",
    "                        subsample         = subsample,\n",
    "                        eta               = eta,\n",
    "                        reg_alpha         = reg_alpha,\n",
    "                        reg_lambda        = reg_lambda,\n",
    "                        n_estimators      = n_estimators,\n",
    "                        max_delta_step    = max_delta_step,\n",
    "                        max_leaves        = max_leaves,\n",
    "                        max_bin           = max_bin,\n",
    "                        max_cat_threshold = max_cat_threshold,\n",
    "                        grow_policy       = grow_policy,\n",
    "                        booster           = booster,\n",
    "                        scale_pos_weight  = scale_pos_weight)\n",
    "cbbb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8571883838585029\n",
      "F1 score: 0.49228154652315537\n",
      "Recall: 0.973305954825462\n",
      "Precision: 0.3294578541640339\n",
      "CPU times: user 4.27 s, sys: 237 ms, total: 4.51 s\n",
      "Wall time: 141 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "print(\"Accuracy:\" ,accuracy_score(  y_train, cbbb.predict(x_train))) #Accuracy: 0.998776450266302\n",
    "print(\"F1 score:\" ,f1_score(        y_train, cbbb.predict(x_train))) #F1 score: 0.37065637065637064\n",
    "print(\"Recall:\"   ,recall_score(    y_train, cbbb.predict(x_train))) #Recall: 0.25\n",
    "print(\"Precision:\",precision_score( y_train, cbbb.predict(x_train))) #Precision: 0.7164179104477612"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8529743725932811\n",
      "F1 score: 0.48265389557294713\n",
      "Recall: 0.9763705103969754\n",
      "Precision: 0.3205585725368503\n",
      "CPU times: user 1.89 s, sys: 114 ms, total: 2 s\n",
      "Wall time: 63.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "print(\"Accuracy:\" ,accuracy_score(  y_test, cbbb.predict(x_test))) #Accuracy: 0.998776450266302\n",
    "print(\"F1 score:\" ,f1_score(        y_test, cbbb.predict(x_test))) #F1 score: 0.37065637065637064\n",
    "print(\"Recall:\"   ,recall_score(    y_test, cbbb.predict(x_test))) #Recall: 0.25\n",
    "print(\"Precision:\",precision_score( y_test, cbbb.predict(x_test))) #Precision: 0.7164179104477612"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8564457501369317\n",
      "F1 score: 0.48379588182632055\n",
      "Recall: 0.97264218862491\n",
      "Precision: 0.32197330791229745\n",
      "CPU times: user 1.72 s, sys: 107 ms, total: 1.83 s\n",
      "Wall time: 60.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "print(\"Accuracy:\" ,accuracy_score(  y_out, cbbb.predict(x_out))) #Accuracy: 0.998776450266302\n",
    "print(\"F1 score:\" ,f1_score(        y_out, cbbb.predict(x_out))) #F1 score: 0.37065637065637064\n",
    "print(\"Recall:\"   ,recall_score(    y_out, cbbb.predict(x_out))) #Recall: 0.25\n",
    "print(\"Precision:\",precision_score( y_out, cbbb.predict(x_out))) #Precision: 0.7164179104477612"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura dos dados originais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.02 s, sys: 24.9 ms, total: 1.05 s\n",
      "Wall time: 35.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['proba'] = cbbb.predict_proba(X0)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proba</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SITUACAO</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>116654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           proba\n",
       "SITUACAO        \n",
       "0         116654\n",
       "1           8862"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['SITUACAO','proba']].groupby(['SITUACAO']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.3 ms, sys: 15 µs, total: 24.3 ms\n",
      "Wall time: 22.5 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">proba</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SITUACAO</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>116654.0</td>\n",
       "      <td>0.155548</td>\n",
       "      <td>0.298783</td>\n",
       "      <td>0.001258</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.010202</td>\n",
       "      <td>0.077631</td>\n",
       "      <td>0.966269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8862.0</td>\n",
       "      <td>0.867053</td>\n",
       "      <td>0.122412</td>\n",
       "      <td>0.002886</td>\n",
       "      <td>0.866077</td>\n",
       "      <td>0.898643</td>\n",
       "      <td>0.920186</td>\n",
       "      <td>0.968509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             proba                                                    \\\n",
       "             count      mean       std       min       25%       50%   \n",
       "SITUACAO                                                               \n",
       "0         116654.0  0.155548  0.298783  0.001258  0.005333  0.010202   \n",
       "1           8862.0  0.867053  0.122412  0.002886  0.866077  0.898643   \n",
       "\n",
       "                              \n",
       "               75%       max  \n",
       "SITUACAO                      \n",
       "0         0.077631  0.966269  \n",
       "1         0.920186  0.968509  "
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df[['SITUACAO','proba']].groupby(['SITUACAO']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.55 ms, sys: 4.13 ms, total: 6.68 ms\n",
      "Wall time: 4.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.loc[ df['proba']>=0.75 ,'PRED'] = 1\n",
    "df.loc[ df['proba'] <0.75 ,'PRED'] = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"metricas\"></a>\n",
    "\n",
    "\n",
    "# 3) Métricas\n",
    "  \n",
    "- ir para [Menu Principal](#navegacao)\n",
    "\n",
    "<a name=\"amostra\"></a>\n",
    "\n",
    "\n",
    "## 3.1) Métricas na Amostra\n",
    "  \n",
    "- ir para [Menu Principal](#navegacao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for test:\n",
      "[[101582  15072]\n",
      " [   571   8291]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusao_pop = confusion_matrix(df['SITUACAO'], df['PRED'])\n",
    "print(\"Confusion matrix for test:\\n%s\" % confusao_pop )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8753704706969629\n",
      "F1 score: 0.5145694336695112\n",
      "Recall: 0.9355675919656963\n",
      "Precision: 0.3548773702007448\n",
      "CPU times: user 175 ms, sys: 18 µs, total: 175 ms\n",
      "Wall time: 171 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "print(\"Accuracy:\" , accuracy_score(df['SITUACAO'], df['PRED'])) \n",
    "print(\"F1 score:\" , f1_score(df['SITUACAO'], df['PRED'])) \n",
    "print(\"Recall:\"   , recall_score(df['SITUACAO'], df['PRED'])) \n",
    "print(\"Precision:\", precision_score(df['SITUACAO'], df['PRED'])) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"falsopos\"></a>\n",
    "\n",
    "## 3.2) Taxa de Falso Positivo\n",
    "  \n",
    "- ir para [Menu Principal](#navegacao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPR: 0.12920259913933513\n",
      "TPR: 0.9355675919656963\n",
      "CPU times: user 138 µs, sys: 7 µs, total: 145 µs\n",
      "Wall time: 152 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tn, fp, fn, tp = confusao_pop.ravel()\n",
    "print('FPR:', fp/(fp + tn))\n",
    "print('TPR:', tp/(tp + fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "417b098a34c1d15f54821650e8824b8f9a13757cdf07902482f1dffeb55d10e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
